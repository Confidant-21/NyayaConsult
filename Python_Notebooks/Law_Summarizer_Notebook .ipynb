{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3920d36-138d-4b99-b0d3-0f50ad9e7ef5",
   "metadata": {},
   "source": [
    "# Installing System Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac0e04f-1543-43d0-91de-77660d476e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/swastikgupta/.conda/envs/law/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b006a29-58ba-4673-bc87-dc6352cbae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pandas) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pandas]‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9aa1a7-9029-40e1-9cd2-f6daa0692589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-4.1.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-genai<2.0.0,>=1.56.0 (from langchain-google-genai)\n",
      "  Downloading google_genai-1.56.0-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-google-genai) (1.2.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-google-genai) (2.12.5)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.0)\n",
      "Collecting google-auth<3.0.0,>=2.45.0 (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.2)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: certifi in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.5.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.6.2)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading langchain_google_genai-4.1.2-py3-none-any.whl (65 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_genai-1.56.0-py3-none-any.whl (426 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "Downloading cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: filetype, websockets, sniffio, pyasn1, distro, cachetools, rsa, pyasn1-modules, google-auth, google-genai, langchain-google-genai\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/11\u001b[0m [langchain-google-genai]32m 9/11\u001b[0m [google-genai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cachetools-6.2.4 distro-1.9.0 filetype-1.2.0 google-auth-2.45.0 google-genai-1.56.0 langchain-google-genai-4.1.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 sniffio-1.3.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langchain-google-genai --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e8525f-a3ff-4043-88f5-4643104cb2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (1.2.5)\n",
      "Requirement already satisfied: langchain-text-splitters in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (0.5.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langchain-core langchain-text-splitters --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0fdc2bb-c6c9-4e9e-b8c3-666b492f786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Using cached langchain-1.2.0-py3-none-any.whl (102 kB)\n",
      "Installing collected packages: langchain\n",
      "Successfully installed langchain-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain --no-deps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebdff3-29a0-483c-8ad3-383975e4dd40",
   "metadata": {},
   "source": [
    "# Importing Google_Api_key_using_(.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef199b86-63d8-45a5-b5dc-23d5f7989b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41b3332-a042-45ec-af5e-344c58aab15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GOOGLE_API_KEY loaded\n"
     ]
    }
   ],
   "source": [
    "if google_api_key:\n",
    "    print(\"‚úÖ GOOGLE_API_KEY loaded\")\n",
    "else:\n",
    "    print(\"‚ùå GOOGLE_API_KEY NOT found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6298f-5f5d-4e66-92f8-3e9205dad676",
   "metadata": {},
   "source": [
    "# Langchain LLM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5abb96db-fdcc-49c6-8f05-94fb94ce4b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're reading a long, complex sentence and trying to understand it fully:\n",
      "\n",
      "\"The animal didn't cross the street because **it** was too tired.\"\n",
      "\n",
      "To understand what \"**it**\" refers to, your brain automatically looks at the whole sentence, particularly the word \"animal.\" You understand that \"it\" refers to the animal, not the street.\n",
      "\n",
      "**Transformers are like a super-smart computer program that learns to do this automatically and much, much better.**\n",
      "\n",
      "Here's the simple breakdown:\n",
      "\n",
      "1.  **The Problem They Solve:** Old computer programs for language often processed words one by one, sequentially. It was hard for them to remember early parts of a long sentence or understand how distant words related to each other (like \"animal\" and \"it\"). This meant they struggled with context.\n",
      "\n",
      "2.  **The Big Idea: \"Attention\" (The Magic Sauce):**\n",
      "    *   When a Transformer processes a word (like \"it\"), it doesn't just look at that word in isolation.\n",
      "    *   It **looks at *every other word* in the sentence at the same time.**\n",
      "    *   It then figures out **how important or relevant each of those other words is** to understanding the current word (\"it\").\n",
      "    *   So, when it sees \"it,\" it might assign a high \"attention score\" to \"animal\" and low scores to \"street\" or \"because.\" This tells it that \"it\" is likely referring to the \"animal.\"\n",
      "\n",
      "3.  **Key Advantages:**\n",
      "    *   **Context is King:** They understand the full context of a word by seeing its relationships to all other words in the input.\n",
      "    *   **Parallel Processing:** Unlike older models that had to process words one after another, Transformers can essentially look at many words at once. This makes them incredibly fast and powerful, especially with huge amounts of text.\n",
      "    *   **Long-Range Dependencies:** They are very good at connecting words that are far apart in a sentence, which was a major challenge for previous technologies.\n",
      "\n",
      "**In essence:**\n",
      "\n",
      "A Transformer is a neural network architecture that, instead of processing data sequentially, processes it in parallel using a mechanism called **self-attention**. This \"self-attention\" allows it to weigh the importance of different parts of the input data relative to each other, thus understanding the context and relationships between all pieces of information simultaneously.\n",
      "\n",
      "**Think of it like this:**\n",
      "\n",
      "If you're making a complex dish, an old computer might only focus on one ingredient at a time. A Transformer, however, looks at *all* the ingredients on the counter, understands how each one relates to the others, and knows exactly which ones are most important for the current step in the recipe.\n",
      "\n",
      "This ability to understand context and relationships across an entire input is why Transformers have revolutionized AI applications like:\n",
      "\n",
      "*   **Language Translation** (Google Translate)\n",
      "*   **Text Generation** (ChatGPT, DALL-E text prompts)\n",
      "*   **Summarization**\n",
      "*   **Chatbots**\n",
      "*   **Code Generation**\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Use the latest stable model version\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", # or \"gemini-2.5-pro\" for complex tasks\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Explain transformers in simple terms\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f5110-d00d-40b5-995a-8d5604c87934",
   "metadata": {},
   "source": [
    "# High Level Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99a91991-0892-42c0-8d20-7de3a40126c5",
   "metadata": {},
   "source": [
    "User Query\n",
    "   ‚Üì\n",
    "Conversation Memory (chat history)\n",
    "   ‚Üì\n",
    "Retriever (Vector DB)\n",
    "   ‚Üì\n",
    "Prompt (history + retrieved docs)\n",
    "   ‚Üì\n",
    "Gemini LLM\n",
    "   ‚Üì\n",
    "Answer\n",
    "   ‚Üì\n",
    "Conversation Memory updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1b35d-3887-4d82-b7df-bc5901024f87",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e714cac-f08e-4681-b80a-6ca3e1a32083",
   "metadata": {},
   "source": [
    "PDF\n",
    " ‚Üì\n",
    "Docling (layout-aware parsing)\n",
    " ‚Üì\n",
    "Markdown (.md)\n",
    " ‚Üì\n",
    "Chunking (semantic-aware)\n",
    " ‚Üì\n",
    "Embeddings\n",
    " ‚Üì\n",
    "FAISS Vector Store\n",
    " ‚Üì\n",
    "Retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b85f4b-b6fc-470d-b5c8-569df1d42ae1",
   "metadata": {},
   "source": [
    "## Step 0: We have our Knowlege in the form of Markdown files (.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48114278-06c0-4fd8-aeeb-082cc05ba273",
   "metadata": {},
   "source": [
    "## Step 1: Loading the .md files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93117261-1321-4295-a0a4-bb4bdea508b9",
   "metadata": {},
   "source": [
    "### LangChain works with a standard object called Document.\n",
    "\n",
    "Each Document =\n",
    "üìÑ text + üè∑Ô∏è metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901d7d0e-bf96-42f8-a818-60b0f1a94360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "docs = []\n",
    "\n",
    "for md_file in Path(\"Markdown Files\").glob(\"*.md\"):\n",
    "    loader = TextLoader(str(md_file), encoding=\"utf-8\")\n",
    "    docs.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558c1d1c-fa1f-4b0b-b61a-52a7a42d0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![Image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFUAAACTCAIAAABwJsKkAABezElEQVR4nOW9ZXhT2d4+vHdcGm2apJq6G/WWQoEWK06huMwMDAzQGXSYoejAoIO7+2CDFyhF6+6uaZtG2iZN4579/7DO4XDmmcPIM+e5rvd6F1/SkJ3sey/72X0vGEEQ6P/HDfPf+FKr1WqxWDAYDIIgKBRKpVLBMIzBYBQKhUKhwGAwfD5frVY7OjoyGAwYhnE4nEajYTAYRCIRgiAcDqfVavV6PQ6HYzKZCILAMAzD8H/jVv8r+GEYVigUb9++FQgErq6u9+/f1+v1dDpdJBLJZDKj0UihUCgUSk9PDx6PR6PRVCoVgiCj0ejs7KxQKOzt7QUCgVKpdHNz+/rrr4cMGYLFYv8b9wn97fgRBLFYLFar9aeffrp586bJZLJarTQaLSkpqaGhQSKRrF+/3mg0MhiM6OjozZs3BwUFWSyWwcFBd3f3p0+fzpkzp6am5vTp0ywWi8lkZmdnd3Z2njlzJjAw0Gq1olCov/duob8dv9VqNZvNdXV1jx49srGxmTp1qoeHh62tbUJCApFIvHXrlpOTk4+Pz8OHD93c3BwcHMaNG6dWq8vLywMDA/v6+kaNGpWfn//ZZ599+eWXDAbj5s2bhw8f3rhx48mTJ52cnP4b+P/mb4RhGI/Hl5SUqNXqefPm7dixY/HixdOmTcNisS0tLVOmTOnr60Oj0Q0NDSKRqLOzs6mpyWq1Go3Gvr4+sVjc0dHBZDJnz5599uzZzs7OBQsWODg41NTUFBYWYjD/lan6949/BEFoNBqZTI6Li5PL5dXV1UQiUaFQNDQ0aDQaEomUl5fX0tLS1NSEx+NlMplOp1Or1eDPrq4uKpVaW1s7evRos9l8//59pVIJw7DRaPx77/NDg//g/gcmNgzDaDQavGOxWD68/tAsFovZbB4YGEhOTg4JCYmPj09MT\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d580a333-7a8a-4ed8-94e9-c953d12718ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Content Preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Markdown Files/Indian_Constitution.md</td>\n",
       "      <td>{'source': 'Markdown Files/Indian_Constitution...</td>\n",
       "      <td>![Image](data:image/png;base64,iVBORw0KGgoAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Markdown Files/Indian_Criminal_Law.md</td>\n",
       "      <td>{'source': 'Markdown Files/Indian_Criminal_Law...</td>\n",
       "      <td>![Image](data:image/png;base64,iVBORw0KGgoAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Markdown Files/Indian_Criminal_Law_2.md</td>\n",
       "      <td>{'source': 'Markdown Files/Indian_Criminal_Law...</td>\n",
       "      <td>![Image](data:image/png;base64,iVBORw0KGgoAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Markdown Files/Indian_Criminal_Law_3.md</td>\n",
       "      <td>{'source': 'Markdown Files/Indian_Criminal_Law...</td>\n",
       "      <td>![Image](data:image/png;base64,iVBORw0KGgoAAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Markdown Files/Contract_Laws.md</td>\n",
       "      <td>{'source': 'Markdown Files/Contract_Laws.md'}</td>\n",
       "      <td>SECTIONS PREAMBLE  1. Short title.  Extent.  C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Source  \\\n",
       "0    Markdown Files/Indian_Constitution.md   \n",
       "1    Markdown Files/Indian_Criminal_Law.md   \n",
       "2  Markdown Files/Indian_Criminal_Law_2.md   \n",
       "3  Markdown Files/Indian_Criminal_Law_3.md   \n",
       "4          Markdown Files/Contract_Laws.md   \n",
       "\n",
       "                                            Metadata  \\\n",
       "0  {'source': 'Markdown Files/Indian_Constitution...   \n",
       "1  {'source': 'Markdown Files/Indian_Criminal_Law...   \n",
       "2  {'source': 'Markdown Files/Indian_Criminal_Law...   \n",
       "3  {'source': 'Markdown Files/Indian_Criminal_Law...   \n",
       "4      {'source': 'Markdown Files/Contract_Laws.md'}   \n",
       "\n",
       "                                     Content Preview  \n",
       "0  ![Image](data:image/png;base64,iVBORw0KGgoAAAA...  \n",
       "1  ![Image](data:image/png;base64,iVBORw0KGgoAAAA...  \n",
       "2  ![Image](data:image/png;base64,iVBORw0KGgoAAAA...  \n",
       "3  ![Image](data:image/png;base64,iVBORw0KGgoAAAA...  \n",
       "4  SECTIONS PREAMBLE  1. Short title.  Extent.  C...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Convert the list of Document objects into a list of dictionaries\n",
    "data = []\n",
    "for doc in docs:\n",
    "    data.append({\n",
    "        \"Source\": doc.metadata.get(\"source\"),\n",
    "        \"Metadata\": doc.metadata,\n",
    "        \"Content Preview\": doc.page_content[:200].replace(\"\\n\", \" \") + \"...\" # Truncate for readability\n",
    "    })\n",
    "\n",
    "# 2. Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 3. Display the table\n",
    "# Using head() to avoid a giant table if you have hundreds of files\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ddc0b-43f3-4abd-8ba2-c70eeda791bb",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning Docling Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86b471-f4a1-4300-a49e-9685fcdbf91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_markdown_for_legal_chunking(text):\n",
    "    # 1. Remove Images & Docling OCR noise (Do this FIRST)\n",
    "    text = re.sub(r'!\\[([^\\]]*)\\]\\([^\\)]+\\)', '', text) # Standard MD images\n",
    "    text = re.sub(r'!Image\\s+[^\\n]+', '', text)        # OCR \"!Image\" tags\n",
    "    \n",
    "    # 2. Remove Links but keep text\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "    \n",
    "    # 3. Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # 4. Remove Mojibake/Scrambled Noise\n",
    "    text = re.sub(r'¬£√â√â¬Æi√â|B√âE√â|¬∫√â√Ü√â√ä¬¥√âv√â√âx√â', '', text)\n",
    "    \n",
    "    # 5. Normalize Whitespace\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "\n",
    "    # 6. MODIFIED Part E: \n",
    "    # Remove ONLY bold/italic markers (*, _) and dividers (---), \n",
    "    # but EXPLICITLY KEEP the # symbols for headers.\n",
    "    text = re.sub(r'[*_]{1,}', '', text)  # Remove bold/italic stars and underscores\n",
    "    text = re.sub(r'[-]{3,}', '', text)   # Remove horizontal lines (---)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0eace-7d13-442a-882d-011cf782bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    doc.page_content = clean_markdown_for_legal_chunking(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61d831-ee06-4728-a39f-193a98dc67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "for doc in docs:\n",
    "    data1.append({\n",
    "        \"Source\": doc.metadata.get(\"source\"),\n",
    "        \"Metadata\": doc.metadata,\n",
    "        \"Content Preview\": doc.page_content[:200].replace(\"\\n\", \" \") + \"...\" # Truncate for readability\n",
    "    })\n",
    "\n",
    "# 2. Create the DataFrame\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# 3. Display the table\n",
    "# Using head() to avoid a giant table if you have hundreds of files\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c30b3-edb7-4904-a216-68535f64f12c",
   "metadata": {},
   "source": [
    "## Step 3: Chunking the docs for Embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa77041-4fc3-49aa-83f3-e30764fdefa4",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers = [\n",
    "    (\"#\", \"Law_Title\"),\n",
    "    (\"##\", \"Chapter_or_Part\"),\n",
    "    (\"###\", \"Section_or_Article\")\n",
    "]\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers)\n",
    "\n",
    "md_chunks = splitter.split_text(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf7c911b-7877-4e57-a399-e7b1acc7d9a8",
   "metadata": {},
   "source": [
    "#test\n",
    "\n",
    "for i, chunk in enumerate(md_chunks[:300]):\n",
    "    print(f\"--- CHUNK {i+1} ---\")\n",
    "    print(f\"METADATA: {chunk.metadata}\")\n",
    "    print(f\"CONTENT PREVIEW: {chunk.page_content[:200]}...\") # First 200 chars\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "883e78ed-cccc-4810-b6ed-8bab622fc3ee",
   "metadata": {},
   "source": [
    "#test\n",
    "\n",
    "all_law_chunks = []\n",
    "\n",
    "for doc in docs:\n",
    "    # 1. Get the book name from the filename automatically\n",
    "    # e.g., 'law_md/constitution.md' -> 'constitution'\n",
    "    file_name = doc.metadata.get(\"source\", \"unknown_law\")\n",
    "    law_label = file_name.split(\"/\")[-1].replace(\".md\", \"\").upper()\n",
    "    \n",
    "    # 2. Split the current book\n",
    "    chunks = splitter.split_text(doc.page_content)\n",
    "    \n",
    "    # 3. Add dynamic metadata to each chunk\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"law_type\"] = law_label\n",
    "        chunk.metadata[\"source\"] = file_name\n",
    "        all_law_chunks.append(chunk)\n",
    "\n",
    "print(f\"Total chunks created: {len(all_law_chunks)}\")\n",
    "print(f\"Sample metadata: {all_law_chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c70a4106-7828-4827-a283-f9c32497df7a",
   "metadata": {},
   "source": [
    "#test\n",
    "\n",
    "for i, chunk in enumerate(all_law_chunks[:3]):\n",
    "    print(f\"--- CHUNK {i+1} ---\")\n",
    "    print(f\"METADATA: {chunk.metadata}\")\n",
    "    print(f\"CONTENT PREVIEW: {chunk.page_content[:200]}...\") # First 200 chars\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "277fd569-be9b-4966-8481-8a4787b3520f",
   "metadata": {},
   "source": [
    "#test\n",
    "len(all_law_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b2511-8265-4001-a75b-6b4c3e7f145b",
   "metadata": {},
   "source": [
    "## Actual Chunking Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edcc2fad-ae79-4072-9d8d-987384247a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks Created: 3367\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. Define the Cleaning Function (Fixed for the \"i\" issue)\n",
    "def clean_legal_md(text):\n",
    "    text = re.sub(r'!\\[([^\\]]*)\\]\\([^\\)]+\\)', '', text) # Remove MD Images\n",
    "    text = re.sub(r'!Image\\s+[^\\n]+', '', text)        # Remove OCR \"Image\" tags\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text) # Remove links, keep text\n",
    "    # Clean only non-alphabet/non-Hindi symbols (Keep 'i')\n",
    "    text = re.sub(r'[¬£√â¬Æ¬∫√Ü√â√äv√âB√âE√â]', '', text) \n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 2. Setup the Splitters\n",
    "# Stage 1: Structural (Header) Splitter\n",
    "headers = [(\"#\", \"Law_Title\"), (\"##\", \"Section_Article\")]\n",
    "header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers)\n",
    "\n",
    "# Stage 2: Character (Safety) Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    ")\n",
    "\n",
    "# 3. The Execution Loop\n",
    "all_final_documents = []\n",
    "\n",
    "for doc in docs:\n",
    "    # A. Clean the text\n",
    "    cleaned_content = clean_legal_md(doc.page_content)\n",
    "    \n",
    "    # B. Extract Law Name from filename (e.g., 'ipc.md' -> 'IPC')\n",
    "    file_path = doc.metadata.get(\"source\", \"Unknown_Law\")\n",
    "    law_name = file_path.split(\"/\")[-1].replace(\".md\", \"\").upper()\n",
    "    \n",
    "    # C. Split by Headers first (This creates the initial Document objects)\n",
    "    header_docs = header_splitter.split_text(cleaned_content)\n",
    "    \n",
    "    # D. Sub-split large sections and inherit metadata\n",
    "    # The 'split_documents' method keeps the Law_Title/Section_Article metadata!\n",
    "    final_chunks = text_splitter.split_documents(header_docs)\n",
    "    \n",
    "    # E. Add File Source to Metadata\n",
    "    for chunk in final_chunks:\n",
    "        chunk.metadata[\"law_type\"] = law_name\n",
    "        chunk.metadata[\"file_source\"] = file_path\n",
    "        all_final_documents.append(chunk)\n",
    "\n",
    "print(f\"Total Chunks Created: {len(all_final_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0dca5aa-6336-4269-929f-2763f7571dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Chunk Size: 777.33 characters\n",
      "Max Chunk Size: 1008 characters\n",
      "Min Chunk Size: 1 characters\n"
     ]
    }
   ],
   "source": [
    "# Checking Chunks info\n",
    "import numpy as np\n",
    "\n",
    "chunk_lengths = [len(c.page_content) for c in all_final_documents]\n",
    "print(f\"Average Chunk Size: {np.mean(chunk_lengths):.2f} characters\")\n",
    "print(f\"Max Chunk Size: {max(chunk_lengths)} characters\")\n",
    "print(f\"Min Chunk Size: {min(chunk_lengths)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76531b98-0618-4f53-8e1f-89e8a9c549d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CHUNK 1 ---\n",
      "METADATA: {'Section_Article': 'i ¬¥x', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: [ 1 , 2024 ]...\n",
      "------------------------------\n",
      "--- CHUNK 2 ---\n",
      "METADATA: {'Section_Article': 'TH CONSTITUTION OF INDIA', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: [ As on 1 st May , 2024]  \n",
      "2024  \n",
      "GOVRNMNT OF INDIA MINISTRY OF LAW AND JUSTIC LGISLATIV DPARTMNT, OFFICIAL LANGUAGS WING...\n",
      "------------------------------\n",
      "--- CHUNK 3 ---\n",
      "METADATA: {'Section_Article': 'PRFAC', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: This is the sixth pocket size edition of the Constitution of India in the diglot form. In this edition, the text of the Constitution of India has been brought up-to-date by incorporating therein all t...\n",
      "------------------------------\n",
      "--- CHUNK 4 ---\n",
      "METADATA: {'Section_Article': 'PRFAC', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: Secretary to the Goernment of India.  \n",
      "LIST OF ARVIATIONS USD  \n",
      "Art., arts. ....................................................  \n",
      "for  \n",
      "Cl., cls. .................................................... ...\n",
      "------------------------------\n",
      "--- CHUNK 5 ---\n",
      "METADATA: {'Section_Article': 'PRFAC', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: Constitution Order.  \n",
      "Inserted.  \n",
      "Page, pages.  \n",
      "Part.  \n",
      "Repealed.  \n",
      "Section, sections.  \n",
      "Schedule.  \n",
      "Substituted.  \n",
      "with effect from.  \n",
      "with etrospectie effect from.  \n",
      "r...\n",
      "------------------------------\n",
      "--- CHUNK 6 ---\n",
      "METADATA: {'Section_Article': 'ARTICLS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: 1. Name and territory of the Union.\n",
      "2. Admission or establishment of new States.\n",
      "3. [2A. Sikkim to be associated with the Union.Omitted. ]\n",
      "3. Formation of new States and alteration of areas, boundarie...\n",
      "------------------------------\n",
      "--- CHUNK 7 ---\n",
      "METADATA: {'Section_Article': 'CITIZNSHIP', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: 5. Citizenship at the commencement of the Constitution.\n",
      "6. Rights of citizenship of certain persons who hae migrated to India from Pakistan.\n",
      "7. Rights of citizenship of certain migrants to Pakistan.\n",
      "8...\n",
      "------------------------------\n",
      "--- CHUNK 8 ---\n",
      "METADATA: {'Section_Article': 'TH CONSTITUTION OF INDIA', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_...\n",
      "------------------------------\n",
      "--- CHUNK 9 ---\n",
      "METADATA: {'Section_Article': 'CONTNTS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_...\n",
      "------------------------------\n",
      "--- CHUNK 10 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | (ii) | Contents |\n",
      "|----------|----------------------------------------------------------------------------------------------------------------|\n",
      "| ARTICLS | PART III |\n",
      "| 12. | Definition. Laws incons...\n",
      "------------------------------\n",
      "--- CHUNK 11 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 23. | Prohibition of traffic in human beings and forced labour. |\n",
      "| 24. | Prohibition of employment of children in factories, etc. |\n",
      "| | Right to Freedom of Religion |\n",
      "| 25. | Freedom of conscience ...\n",
      "------------------------------\n",
      "--- CHUNK 12 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | [31. | Compulsory acquisition of property- Omitted .] |\n",
      "| Saing of Certain Laws | Saing of Certain Laws |\n",
      "| 31A. | Saing of Laws proiding for acquisition of estates, etc. |\n",
      "| 31. | Validation of cer...\n",
      "------------------------------\n",
      "--- CHUNK 13 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 35. | Legislation to gie effect to the proisions of this Part. |\n",
      "| PART IV | PART IV |\n",
      "| 36. | Definition. |\n",
      "| 37. | Application of the principles contained in this Part. |\n",
      "| 38. | State to secure a...\n",
      "------------------------------\n",
      "--- CHUNK 14 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 43. | Promotion of co-operatie societies. |\n",
      "| 44. | Uniform ciil code for the citizens. |\n",
      "| 45. | Proision for early childhood care and education to children below the age of six years. |\n",
      "| 46. | Pr...\n",
      "------------------------------\n",
      "--- CHUNK 15 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 52. | The President of India. |\n",
      "| 53. | xecutie power of the Union. |\n",
      "| 54. | lection of President. |  \n",
      "| () | Contents |\n",
      "|----------|----------------------------------------------------------------...\n",
      "------------------------------\n",
      "--- CHUNK 16 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 63. | The Vice-President of India. |\n",
      "| 64. | The Vice-President to be ex officio Chairman of the Council of States. |\n",
      "| 65. | The Vice-President to act as President or to discharge his functions dur...\n",
      "------------------------------\n",
      "--- CHUNK 17 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 73. | xtent of executie power of the Union. |\n",
      "| Council | of Ministers |\n",
      "| 74. | Council of Ministers to aid and adise President . |\n",
      "| 75. | Other proisions as to Ministers. |\n",
      "| | The Attorney-Gener...\n",
      "------------------------------\n",
      "--- CHUNK 18 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 84. | Qualification for membership of Parliament. |\n",
      "| 85. | Sessions of Parliament, prorogation and dissolution. |\n",
      "| 86. | Right of President to address and send messages to Houses. |\n",
      "| 87. | Specia...\n",
      "------------------------------\n",
      "--- CHUNK 19 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 95. | Power of the Deputy Speaker or other person to perform the duties of the office of, or to act as, Speaker. |  \n",
      "| (ii) | Contents |\n",
      "|-----------|------------------------------------------------...\n",
      "------------------------------\n",
      "--- CHUNK 20 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 104. | Penalty for sitting and oting before making oath or affirmation |\n",
      "| | under article 99 or when not qualified or when disqualified. |\n",
      "| 105. | Powers, priileges, etc., of the Houses of Parliam...\n",
      "------------------------------\n",
      "--- CHUNK 21 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 116. | Votes on account, otes of credit and exceptional grants. |\n",
      "| 117. | Special proisions as to financial ills. |\n",
      "| | Procedure Generally |\n",
      "| 118. | Rules of procedure. |\n",
      "| 119. | Regulation by l...\n",
      "------------------------------\n",
      "--- CHUNK 22 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 127. | Appointment of ad hoc Judges. |\n",
      "| 128. | Attendance of retired Judges at sittings of the Supreme Court. |\n",
      "| 129. | Supreme Court to be a court of record. |\n",
      "| 130. | Seat of Supreme Court. |\n",
      "|...\n",
      "------------------------------\n",
      "--- CHUNK 23 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | ARTICLS | |\n",
      "| 134A. | Certificate for appeal to the Supreme Court. |\n",
      "| 135. | Jurisdiction and powers of the Federal Court under existing law to be exercisable by the Supreme Court. |\n",
      "| 136. | Speci...\n",
      "------------------------------\n",
      "--- CHUNK 24 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | [144A. | Special proisions as to disposal of questions relating to constitutional alidity of laws. Omitted .] |\n",
      "| 145. | Rules of Court, etc. |\n",
      "| 146. | Officers and serants and the expenses of the ...\n",
      "------------------------------\n",
      "--- CHUNK 25 ---\n",
      "METADATA: {'Section_Article': 'TH UNION AND ITS TRRITORY', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 157. | Qualifications for appointment as Goernor. |\n",
      "| 158. | Conditions of Goernor's office. |\n",
      "| 159. | Oath or affirmation by the Goernor. |\n",
      "| 160. | Discharge of the functions of the Goernor in ce...\n",
      "------------------------------\n",
      "--- CHUNK 26 ---\n",
      "METADATA: {'Section_Article': 'ARTICLS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 171. | Composition of the Legislatie Councils. |\n",
      "|------------------------------|---------------------------------------------------------------------------------------------------------------------...\n",
      "------------------------------\n",
      "--- CHUNK 27 ---\n",
      "METADATA: {'Section_Article': 'ARTICLS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 180. | Power of the Deputy Speaker or other person to perform the duties of the office of, or to act as, Speaker. |\n",
      "| 181. | The Speaker or the Deputy Speaker not to preside while a resolution for h...\n",
      "------------------------------\n",
      "--- CHUNK 28 ---\n",
      "METADATA: {'Section_Article': 'ARTICLS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 187. | Secretariat of State Legislature. |\n",
      "| Conduct of usiness | Conduct of usiness |\n",
      "| 188. | Oath or affirmation by members. |\n",
      "| 189. | Voting in Houses, power of Houses to act notwithstanding ac...\n",
      "------------------------------\n",
      "--- CHUNK 29 ---\n",
      "METADATA: {'Section_Article': 'ARTICLS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 195. | Salaries and allowances of members. |\n",
      "| | Legislatie Procedure |\n",
      "| 196. | Proisions as to introduction and passing of ills. |\n",
      "| 197. | Restriction on powers of Legislatie Council as to ills o...\n",
      "------------------------------\n",
      "--- CHUNK 30 ---\n",
      "METADATA: {'Section_Article': 'ARTICLS', 'law_type': 'INDIAN_CONSTITUTION', 'file_source': 'Markdown Files/Indian_Constitution.md'}\n",
      "CONTENT PREVIEW: | 209. | Regulation by law of procedure in the Legislature of the State in relation to financial business. |  \n",
      "| (xiii) | Contents |\n",
      "|----------|-------------------------------------------------------...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(all_final_documents[:30]):\n",
    "    print(f\"--- CHUNK {i+1} ---\")\n",
    "    print(f\"METADATA: {chunk.metadata}\")\n",
    "    print(f\"CONTENT PREVIEW: {chunk.page_content[:200]}...\") # First 200 chars\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c1453-7451-4ccc-aec3-95a52ee4ad1c",
   "metadata": {},
   "source": [
    "## Step 4: Setting up Embadding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1738ab-dfee-4625-9ada-5e07db52e20c",
   "metadata": {},
   "source": [
    "## Embadding Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d140b69-0dad-470b-a527-1b186faa59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "print(len(embeddings.embed_query(\"Indian Penal Code\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70740601-0f0e-4665-bc92-6078bdf510f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_final_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[43mall_final_documents\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'all_final_documents' is not defined"
     ]
    }
   ],
   "source": [
    "type(all_final_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607647b4-f602-44cf-9bcb-59683cbaf330",
   "metadata": {},
   "source": [
    "## Step 5: Creaing VectoreStore FIASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e52383-c286-4678-912c-96f73349eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c635f4b-e6da-40f9-a862-dd260ee564d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_final_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m vectorstore = FAISS.from_documents(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     documents=\u001b[43mall_final_documents\u001b[49m,\n\u001b[32m      3\u001b[39m     embedding=embeddings\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'all_final_documents' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=all_final_documents,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ed367-b69d-4ed5-93e8-b41c175a54ae",
   "metadata": {},
   "source": [
    "## Step 6: Saving the Vetor Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3dec22-660c-4a6e-ba65-409ab5fd9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"law_faiss_store\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1eac7d-76cd-41bf-a0d1-54ac41a4e9d1",
   "metadata": {},
   "source": [
    "## Step 7: Creating a Retreaver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae5f6357-edf5-4de5-8b71-98fd105ca77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9881fb-82bd-4a8d-97be-23bfed66870f",
   "metadata": {},
   "source": [
    "## Step 8: Creating a Google Gemini(llm) Instense for Law with temperature 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b1d7597-6eee-47c9-8e03-8d8d66f8499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_law = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", # or \"gemini-2.5-pro\" for complex tasks\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f62f07-aa2b-4df9-bef2-2334b97e26ae",
   "metadata": {},
   "source": [
    "## Step 9: Creating a Memory for Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62460f4-6e1a-43ad-b185-7fac5bdf4e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 1.2.0\n",
      "Path: /home/swastikgupta/.conda/envs/law/lib/python3.11/site-packages/langchain/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(f\"Version: {langchain.__version__}\")\n",
    "print(f\"Path: {langchain.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d482e44f-6efc-4516-9714-f3b6b07ba93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_law_domain(text: str):\n",
    "    \"\"\"\n",
    "    Detect relevant Indian law domain based on keywords.\n",
    "    Returns a law_type string matching your vector metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    domain_keywords = {\n",
    "        \"IPC\": [\n",
    "            \"murder\", \"theft\", \"assault\", \"cheating\", \"fraud\",\n",
    "            \"criminal\", \"rape\", \"kidnapping\", \"hurt\"\n",
    "        ],\n",
    "        \"CRPC\": [\n",
    "            \"arrest\", \"police\", \"bail\", \"fir\", \"investigation\",\n",
    "            \"custody\", \"warrant\"\n",
    "        ],\n",
    "        \"CPC\": [\n",
    "            \"civil suit\", \"injunction\", \"property dispute\",\n",
    "            \"recovery\", \"damages\"\n",
    "        ],\n",
    "        \"FAMILY\": [\n",
    "            \"divorce\", \"maintenance\", \"alimony\",\n",
    "            \"domestic violence\", \"custody\", \"dowry\"\n",
    "        ],\n",
    "        \"LABOUR\": [\n",
    "            \"termination\", \"salary\", \"notice period\",\n",
    "            \"employment\", \"wages\", \"gratuity\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for domain, keywords in domain_keywords.items():\n",
    "        if any(keyword in text for keyword in keywords):\n",
    "            return domain\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e5b089-6aee-4120-8b28-3d6af58324db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_case_summary(llm, old_summary, user_input, assistant_response):\n",
    "    \"\"\"\n",
    "    Update the running legal case summary using the LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal case summarizer.\n",
    "\n",
    "Existing case summary:\n",
    "{old_summary}\n",
    "\n",
    "New interaction:\n",
    "User: {user_input}\n",
    "Assistant: {assistant_response}\n",
    "\n",
    "Task:\n",
    "Update the case summary by:\n",
    "- Keeping only legally relevant facts\n",
    "- Removing repetition\n",
    "- Writing in third person\n",
    "- Keeping it concise\n",
    "\"\"\"\n",
    "\n",
    "    summary = llm.invoke(prompt).content.strip()\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5318b16d-76eb-4cea-b65f-3c078e9b2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_assistant_chat(\n",
    "    user_query: str,\n",
    "    vectorstore,\n",
    "    llm,\n",
    "    case_summary: str = \"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Chatbot-style legal assistant function.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): User's legal query\n",
    "        vectorstore: FAISS vector store\n",
    "        llm: LLM instance\n",
    "        case_summary (str): Running summarized memory of the case\n",
    "\n",
    "    Returns:\n",
    "        response (str): Assistant reply\n",
    "        updated_case_summary (str): Updated memory summary\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Detect law domain\n",
    "    detected_domain = detect_law_domain(user_query)\n",
    "\n",
    "    # 2. Create retriever (domain-aware if possible)\n",
    "    if detected_domain:\n",
    "        retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\n",
    "                \"k\": 6,\n",
    "                \"filter\": {\"law_type\": detected_domain}\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 6}\n",
    "        )\n",
    "\n",
    "    # 3. Retrieve relevant legal documents\n",
    "    docs = retriever.invoke(user_query)\n",
    "\n",
    "\n",
    "    # 4. Build legal context\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[{d.metadata.get('law_type')} | {d.metadata.get('Section_Article')}]\\n{d.page_content}\"\n",
    "        for d in docs\n",
    "    )\n",
    "\n",
    "    # 5. Prompt construction\n",
    "    prompt = f\"\"\"\n",
    "You are a professional Indian legal assistant.\n",
    "\n",
    "Case summary so far:\n",
    "{case_summary}\n",
    "\n",
    "User query:\n",
    "{user_query}\n",
    "\n",
    "Relevant legal provisions:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Answer strictly based on Indian law\n",
    "- Mention relevant sections\n",
    "- Do not hallucinate\n",
    "- If information is insufficient, ask clarifying questions\n",
    "\"\"\"\n",
    "\n",
    "    # 6. LLM call\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    # 7. Update case summary (memory)\n",
    "    updated_case_summary = update_case_summary(\n",
    "        llm,\n",
    "        case_summary,\n",
    "        user_query,\n",
    "        response\n",
    "    )\n",
    "\n",
    "    return response, updated_case_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b7823dc-0582-446a-b54d-a8e13a6ed74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    folder_path=\"law_faiss_store\",\n",
    "    embeddings=embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e1e45e5-93f7-4701-ab20-af60b864123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_summary = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0779b0-3f8e-4006-ad7b-4197afc5bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the legal provisions provided:\n",
      "\n",
      "1.  **For Government Employees (Civil Servants):**\n",
      "    If you are a member of a civil service of the Union or a State, or hold a civil post under the Union or a State, **Article 311 of the Indian Constitution** provides significant protection.\n",
      "    *   **Article 311(1)** states that you cannot be dismissed or removed by an authority subordinate to that by which you were appointed.\n",
      "    *   **Article 311(2)** mandates that you cannot be dismissed, removed, or reduced in rank *except after an inquiry* where you have been informed of the charges against you and given a reasonable opportunity of being heard in respect of those charges. Termination without such a due process would be unconstitutional for a civil servant.\n",
      "\n",
      "2.  **For Private Sector Employees or Other Cases:**\n",
      "    The provided provisions **do not directly address** the issue of \"termination without notice\" for employees in the private sector or general employment contracts.\n",
      "    *   **[CONTRACT_LAWS | Sections 201, 202]** pertain to the termination of an *agency* relationship, where one person acts on behalf of another, and not typically a standard employer-employee relationship with respect to notice periods for termination of service.\n",
      "    *   The other provisions ([INDIAN_CRIMINAL_LAW_2 | FORM No. 34], [INDIAN_CONSTITUTION | (Part IX.-Co-operatie Societies)], [INDIAN_CRIMINAL_LAW_2 | GNRAL PROVISIONS AS TO INQUIRIS AND TRIALS], [INDIAN_CRIMINAL_LAW_2 | CHAPTR XXXVIII]) are related to criminal procedure, co-operative societies, or general criminal law principles and are not relevant to employment termination without notice.\n",
      "\n",
      "**Conclusion and Clarification Needed:**\n",
      "\n",
      "The provisions supplied only offer protection regarding *due process* for **government employees** under Article 311 of the Constitution. They do not contain specific laws pertaining to notice periods for termination in general employment, particularly in the private sector.\n",
      "\n",
      "To provide a more precise legal assessment, please clarify:\n",
      "\n",
      "*   **Are you a government employee (civil servant) or employed in the private sector?**\n",
      "*   **Do you have an employment contract, and if so, does it specify notice periods for termination?**\n"
     ]
    }
   ],
   "source": [
    "response, case_summary = legal_assistant_chat(\n",
    "    user_query=\"My employer terminated me without notice\",\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm,\n",
    "    case_summary=case_summary\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04173d9b-ed5c-4875-9c79-53c342228b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for clarifying that you were employed by a private company for 3 years.\n",
      "\n",
      "Given this information:\n",
      "1.  **Article 311 of the Indian Constitution**, which offers significant protection against dismissal for government employees (civil servants), **does not apply** to your situation as you were a private sector employee.\n",
      "\n",
      "2.  The legal provisions provided in the prompt ([CONTRACT_LAWS | Illustrations] and [INDIAN_CRIMINAL_LAW_2]) are **not relevant** to your case of termination without notice from a private company.\n",
      "    *   The sections from `CONTRACT_LAWS` (e.g., 257-266, SCHDUL) are either repealed or pertain to partnership law, not general employment contracts.\n",
      "    *   The provisions from `INDIAN_CRIMINAL_LAW_2` relate to criminal procedure, service of summons, and forms for attachment of property, which are entirely distinct from employment termination matters.\n",
      "\n",
      "**Legal Assessment for Private Sector Termination:**\n",
      "In the private sector in India, the terms and conditions of employment, including termination procedures and notice periods, are primarily governed by:\n",
      "*   Your **employment contract** or **appointment letter** (if one exists).\n",
      "*   The **company's service rules or policies**.\n",
      "*   Relevant **labour laws**, which may include:\n",
      "    *   The **Industrial Disputes Act, 1947**, particularly if you fall under the definition of a \"workman\" and the employer is an \"industrial establishment.\" This Act mandates specific procedures and compensation (like notice or pay in lieu thereof) for termination categorized as \"retrenchment\" (Sections 25F, 25N, etc.).\n",
      "    *   The **Shops and Establishments Act** of the specific state where the company is located, which often prescribes minimum notice periods for termination for employees not covered by the Industrial Disputes Act or specific contract terms.\n",
      "\n",
      "To provide a precise legal assessment, I require further information:\n",
      "1.  **Do you have an employment contract or an appointment letter?** If so, what does it state regarding terms for termination, including notice periods for either the employer or employee?\n",
      "2.  **In which state is the private company located?** This is crucial for identifying the applicable state-specific Shops and Establishments Act.\n",
      "3.  **What was your designation/role and the nature of your duties?** This will help determine if the Industrial Disputes Act, 1947, might be applicable to your situation.\n"
     ]
    }
   ],
   "source": [
    "response, case_summary = legal_assistant_chat(\n",
    "    user_query=\"It was a private company and I worked for 3 years\",\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm,\n",
    "    case_summary=case_summary\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef2562-8c65-444a-a056-48b92522b041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (law)",
   "language": "python",
   "name": "law"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
